{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPV7IOoyP5E3PUUm3fl/Qh8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoSiqueiraDS/Joao_Siqueira_DS/blob/master/Day%201\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2es3rh62Kjl",
        "colab_type": "text"
      },
      "source": [
        "# Study of the paper \"A Gentle Introduction to Exploratory Data Analysis\"\n",
        "\n",
        "* You do exploratory data analysis to learn more about the more before you ever run a machine learning model.\n",
        "\n",
        "* You create your own mental model of the data so when you run a machine learning model to make predictions, you’ll be able to recognise whether they’re BS or not. (Dont know yet what is BS but the comment is worth doing)\n",
        "\n",
        "## An EDA checklist\n",
        "\n",
        "1. What question(s) are you trying to solve (or prove wrong)?\n",
        "2. What kind of data do you have and how do you treat different types?\n",
        "3. What’s missing from the data and how do you deal with it?\n",
        "4. Where are the outliers and why should you care about them?\n",
        "5. How can you add, change or remove features to get more out of your data?\n",
        "\n",
        "### EDA doesn’t always have to be done with code, you can use your model of the world to begin with and use code to see if it’s right later.\n",
        "\n",
        "* ... **But what if you had a dataset you’d never seen before.** What if a real estate agent wanted help predicting house prices in their city. You check out their data and find a bunch of columns which you don’t understand.\n",
        "You email the client.\n",
        "\n",
        "‘What does Tnummean?’\n",
        "\n",
        "They respond. ‘Tnum is the number of toilets in a property.’\n",
        "\n",
        "Good to know.\n",
        "\n",
        "When you’re dealing with a new dataset, you won’t always have information available about it as Kaggle provides. This is where you’ll want to seek the knowledge of an SME.\n",
        "\n",
        "Another acronym. Great.\n",
        "\n",
        "## It is a good idea to separate the features in a dataset\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/jr6yp54ep1vfltw/DS_Categories.png?dl=1)\n",
        "\n",
        "\n",
        "\n",
        "###Your first pass of EDA on a dataset should have **the goal of not only raising more questions about the data but to get a model built using the least amount of information possible** so you’ve got have a baseline to work from.\n",
        "\n",
        "\n",
        "### Below there is a good example of a useful function/library to have a ideia of how many holes there are in your data\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/fye8eio9l9hbbex/missingno_example.png?dl=1)\n",
        "\n",
        "* It is important to deal properly with missing values. Machine learning models like more and more data. We cannot just remove the the non_value data. What’s next?\n",
        "* Answer: Imputing values. In other words, filling up the missing data with values calculated from other data.\n",
        "\n",
        "##** Where are the outliers and why you should be paying attention to them?**\n",
        "\n",
        "‘Did you check the distribution?’ Athon asked.\n",
        "‘I did with the first set of data but not the second set…’\n",
        "It hit me.\n",
        "There it was. The rest of the data was being shaped to match the outlier.\n",
        "If you look at the number of occurrences of unique values within a dataset, one of the most common patterns you’ll find is Zipf’s law. It looks like this.\n",
        "\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/49pmms11kgrg5nf/Zipf_law.png?dl=1)\n",
        "\n",
        "\n",
        "Remembering Zipf’s law can help to think about outliers (values towards the end of the tail which don’t occur often are potential outliers).\n",
        "**The definition of an outlier will be different for every dataset. As a general rule of thumb, you may consider anything more than 3 standard deviations away from the mean might be considered an outlier.**\n",
        "\n",
        "![alt](https://www.dropbox.com/s/6uf46zypz56dmcl/normal_curve.png?dl=1)\n",
        "\n",
        "* How do you find outliers?\n",
        "Distribution. Distribution. Distribution. Distribution. Four times is enough (I’m trying to remind myself here).\n",
        "During your first pass of EDA, you should be checking what the distribution of each of your features is.\n",
        "A distribution plot will help represent the spread of different values of data you have across. And more importantly, help to identify potential outliers.\n",
        "\n",
        "\n",
        "##Getting more out of your data with feature engineering\n",
        "\n",
        "The Titanic dataset only has 10 features. But what if your dataset has hundreds? Or thousands? Or more? This isn’t uncommon.\n",
        "During your exploratory data analysis process, once you’ve started to form an understanding AND you’ve got an idea of the distributions AND you’ve found some outliers AND you’ve dealt with them, the next biggest chunk of your time will be spent on feature engineering.\n",
        "\n",
        "* The banana week example ... \n",
        "\n",
        "We know Week 2 is a banana week so we can set it using np.where()\n",
        "df[\"Banana Week\"] = np.where(df[\"Week Number\"] == 2, 1, 0)\n",
        "\n",
        "![alt txt](https://www.dropbox.com/s/k1ff5efo3vupq8j/banana_week.png?dl=1)\n",
        "\n",
        "\n",
        "## Building your first model(s)\n",
        "\n",
        "Finally. We’ve been through a bunch of steps to get our data ready to run some models.\n",
        "If you’re like me, when you started learning data science, this is the part you learned first. All the stuff above had already been done by someone else. All you had to was fit a model on it.\n",
        "Our Titanic dataset is small. So we can afford to run a multitude of models on it to figure out which is the best to use.\n",
        "Notice how I put an (s) in the subtitle, you can pay attention to this one.\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/rt613owi052q8lr/models.png?dl=1)\n",
        "\n",
        "The rest is all about machine learning models ... \n",
        "\n",
        "To finish off ... The EDA circle of life below\n",
        "\n",
        "![alt text](https://www.dropbox.com/s/rjz3oyh3cfaop1x/EDA.png?dl=1)\n",
        "\n",
        "#This is it!\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "thfdfM7I4iTG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}